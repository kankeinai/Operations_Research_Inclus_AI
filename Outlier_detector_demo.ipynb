{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inclus AI â€“ Demo Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    api_key=\"API KEY\", \n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=\"END POINT\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"inclusData.xlsx\") \n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Convert 'Answer' column to numeric, coercing non-numeric values to NaN\n",
    "\n",
    "df2=df[['Item','Comment','Dimension']]\n",
    "\n",
    "df_subset = df2.dropna(subset=['Comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_strings = []\n",
    "\n",
    "# Iterate over each row and format it as desired\n",
    "for index, row in df_subset.iterrows():\n",
    "    formatted_string = f\"ITEM: {row['Item']}, Comment: {row['Comment']}, Dimension: {row['Dimension']}\"\n",
    "    formatted_strings.append(formatted_string)\n",
    "\n",
    "# Concatenate all formatted strings into one long string\n",
    "long_string = '\\n'.join(formatted_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give impact or likelyhood for each comment (based on the Dimension) in scale 0-5 (number can have decimals), print the comment and add the assesment after it, print the risk the comment is related\n"
     ]
    }
   ],
   "source": [
    "benchmark_questions_strict = 'Give impact or likelyhood for each comment (based on the Dimension) in scale 0-5 (number can have decimals), print the comment and add the assesment after it, print the risk the comment is related'\n",
    "\n",
    "print(benchmark_questions_strict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The assistant is a risk analyst.\n",
      "Inclus is a Finnish scaleup company that provides a platform for doing collaborative risk analysis.\n",
      "The data that is provided below is gathered from multiple people within Inclus and concerns multiple risk events. Each risk event is described in a header above the individual assessments. Treat each comment equally.\n",
      "HERES EXAMPLE OF COMMENTS AND VALUATIONS: Impact 0: \"This feature has no significant impact on user experience.\" \"The change will have negligible impact on system performance.\"Impact 1:\"Minor improvements may have a slight impact on customer satisfaction.\"\"The update is expected to have a minimal impact on overall sales.\"Impact 2:\"This decision could have a moderate impact on project timelines.\"\"Changes in marketing strategy may have a moderate impact on brand visibility.\"Impact 3:\"The proposed changes will have a noticeable impact on production efficiency.\"\"Increased competition may have a significant impact on market share.\"Impact 4:\"The new feature is expected to have a substantial impact on user engagement.\"\"Market trends suggest a high impact on pricing strategies.\"Impact 5:\"The security breach had a severe impact on customer trust.\"\"Natural disasters can have a catastrophic impact on supply chain operations.\"\n",
      "Give all the results in format: ***risk type***comment***valuation (only the number), example: ***Outsourcing risks***We havent always been very good at selecting our partners***3.0 \n"
     ]
    }
   ],
   "source": [
    "# Here we define the 'instruction' for the 'system' part for the prompt. Here the data 'risk_data' is also injected into the prompt, but it could be presented elsewhere.\n",
    "prompt_engineering_majick = 'The assistant is a risk analyst.'\n",
    "company_context = 'Inclus is a Finnish scaleup company that provides a platform for doing collaborative risk analysis.'\n",
    "data_context = 'The data that is provided below is gathered from multiple people within Inclus and concerns multiple risk events. Each risk event is described in a header above the individual assessments. Treat each comment equally.'\n",
    "examples = 'HERES EXAMPLE OF COMMENTS AND VALUATIONS: Impact 0: \"This feature has no significant impact on user experience.\" \"The change will have negligible impact on system performance.\"Impact 1:\"Minor improvements may have a slight impact on customer satisfaction.\"\"The update is expected to have a minimal impact on overall sales.\"Impact 2:\"This decision could have a moderate impact on project timelines.\"\"Changes in marketing strategy may have a moderate impact on brand visibility.\"Impact 3:\"The proposed changes will have a noticeable impact on production efficiency.\"\"Increased competition may have a significant impact on market share.\"Impact 4:\"The new feature is expected to have a substantial impact on user engagement.\"\"Market trends suggest a high impact on pricing strategies.\"Impact 5:\"The security breach had a severe impact on customer trust.\"\"Natural disasters can have a catastrophic impact on supply chain operations.\"'\n",
    "formatting = 'Give all the results in format: ***risk type***comment***valuation (only the number), example: ***Outsourcing risks***We havent always been very good at selecting our partners***3.0 '\n",
    "\n",
    "context_for_GPT = [\n",
    "prompt_engineering_majick,\n",
    "company_context,\n",
    "data_context,\n",
    "examples,\n",
    "formatting,\n",
    "long_string\n",
    "]\n",
    "\n",
    "print('\\n'.join(context_for_GPT[:-1]))\n",
    "system_content = '\\n'.join(context_for_GPT) # goes into the prompt in 'messages' part in line '{\"role\": \"system\", \"content\": system_content}' later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_content},\n",
    "        {\"role\": \"user\", \"content\": benchmark_questions_strict} # the first strict benchmark question is asked\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text data containing risk entries\n",
    "risk_data = response.choices[0].message.content\n",
    "\n",
    "# Split the text data into individual risk entries\n",
    "risk_entries = risk_data.strip().split(\"\\n\\n\")\n",
    "\n",
    "risk_entries=risk_entries[:-1]\n",
    "\n",
    "# Initialize empty lists to store components of each risk entry\n",
    "risks = []\n",
    "descriptions = []\n",
    "impacts = []\n",
    "\n",
    "# Iterate through each risk entry and extract its components\n",
    "for entry in risk_entries:\n",
    "    parts = entry.split(\"***\")\n",
    "    risk = parts[1].strip()\n",
    "    description = parts[2].strip()\n",
    "    impact = float(parts[3].strip())  # Convert to float\n",
    "    \n",
    "    # Append components to respective lists\n",
    "    risks.append(risk)\n",
    "    descriptions.append(description)\n",
    "    impacts.append(impact)\n",
    "\n",
    "# Create a DataFrame from the extracted components\n",
    "risk_df = pd.DataFrame({\n",
    "    \"Risk\": risks,\n",
    "    \"Description\": descriptions,\n",
    "    \"Impact\": impacts\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "risk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_df = risk_df.rename(columns={\"Description\": \"Comment\"})\n",
    "\n",
    "# Merge the DataFrames based on the 'Comments' column\n",
    "merged_df = pd.merge(risk_df, df, on=\"Comment\", how=\"outer\")\n",
    "merged_df = merged_df.dropna(subset=['Impact'])\n",
    "# Display the merged DataFrame\n",
    "merged_df=merged_df[['Item','Dimension','Answer', 'Comment', 'Impact']]\n",
    "merged_df = merged_df.rename(columns={\"Answer\": \"Actual Answer\"})\n",
    "merged_df = merged_df.rename(columns={\"Impact\": \"GPT Answer\"})\n",
    "print(merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['GPT Answer'] = merged_df['GPT Answer'].astype(float)\n",
    "merged_df['Actual Answer'] = merged_df['Actual Answer'].astype(float)\n",
    "outliers = merged_df[abs(merged_df['GPT Answer'] - merged_df['Actual Answer']) >= 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
